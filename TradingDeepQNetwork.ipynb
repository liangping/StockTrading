{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKPubIrYyZDE"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASxRamBaKwMy"
   },
   "outputs": [],
   "source": [
    "aapl = pd.read_csv('aapl.us.txt')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Swf2us2zLhUA"
   },
   "outputs": [],
   "source": [
    "aapl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQ5AD7ZVLaHu"
   },
   "outputs": [],
   "source": [
    "train = aapl.iloc[5000:5400].reset_index(drop=True)\n",
    "test = aapl.iloc[5400:5800].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yphhiocILnkR"
   },
   "outputs": [],
   "source": [
    "class TradingEnvironment:\n",
    "    def __init__(self, data, his_len=60):\n",
    "        self.data = data\n",
    "        self.his_len = his_len\n",
    "        self.profits = 0\n",
    "        self.positions = []\n",
    "        self.position_value = 0\n",
    "        self.current_t = 0\n",
    "        self.done = False\n",
    "        self.history = [0 for i in range(self.his_len)]\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.current_t = 0\n",
    "        self.profits = 0\n",
    "        self.positions = []\n",
    "        self.position_value = 0\n",
    "        self.done = False\n",
    "        self.history = [0 for i in range(self.his_len)]\n",
    "        return [self.position_value] + self.history\n",
    "  \n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        if action == 1:\n",
    "            self.positions.append(self.data.iloc[self.current_t, :]['Close'])\n",
    "        elif action == 2:\n",
    "            if len(self.positions) == 0:\n",
    "                reward = -1\n",
    "            else:\n",
    "                profits = 0\n",
    "                for p in self.positions:\n",
    "                    profits += self.data.iloc[self.current_t, :]['Close'] - p\n",
    "                reward += profits\n",
    "                self.profits += profits\n",
    "                self.positions = []\n",
    "        self.current_t += 1\n",
    "        self.position_value = 0\n",
    "        for p in self.positions:\n",
    "            self.position_value += self.data.iloc[self.current_t, :]['Close'] - p\n",
    "        self.history.pop(0)\n",
    "        self.history.append(self.data.iloc[self.current_t, :]['Close'] -\n",
    "                            self.data.iloc[self.current_t - 1, :]['Close'])\n",
    "        if self.current_t == len(self.data) - 1:\n",
    "            done = True\n",
    "        if reward > 0:\n",
    "            reward = 10\n",
    "        elif reward < 0:\n",
    "            reward = -1\n",
    "        return [self.position_value] + self.history, reward, self.done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8cIGIPZUilj"
   },
   "outputs": [],
   "source": [
    "env = TradingEnvironment(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYqKEIorUoRQ"
   },
   "outputs": [],
   "source": [
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, inputs=61, actions=3):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(inputs, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.net(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Buj4WtwrVJDe"
   },
   "outputs": [],
   "source": [
    "Q = Q_Network()\n",
    "Q_b = copy.deepcopy(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jWc-DBDhVlZ9"
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "optimizer = optim.Adam(list(Q.parameters()), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKPeiONeV7Gc"
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "step_max = len(env.data) - 1\n",
    "mem_size = 200\n",
    "batch_size = 50\n",
    "gamma = 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQtHQKJfWICG"
   },
   "outputs": [],
   "source": [
    "memory = []\n",
    "total_step = 0\n",
    "total_rewards = []\n",
    "total_losses = []\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.1\n",
    "epsilon_decrease = 1e-3\n",
    "start_reduce_epsilon = 200\n",
    "train_freq = 10\n",
    "update_q_freq = 20\n",
    "show_log_freq = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhqZN-_tWiXJ"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "for epoch in range(epochs):\n",
    "    pobs = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    total_loss = 0\n",
    "    while not done and step < step_max:\n",
    "        pact = np.random.randint(3)\n",
    "        if np.random.rand() > epsilon:\n",
    "            pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)))\n",
    "            pact = np.argmax(pact.data)\n",
    "            pact = pact.numpy()\n",
    "        obs,reward, done = env.step(pact)\n",
    "        memory.append([pobs, pact, reward, obs, done])\n",
    "        if len(memory) > mem_size:\n",
    "            memory.pop(0)\n",
    "        if len(memory) ==  mem_size:\n",
    "            if total_step % train_freq == 0:\n",
    "            shuffled_memory = np.random.permutation(memory)\n",
    "            memory_idx = range(len(shuffled_memory))\n",
    "            for i in memory_idx[::batch_size]:\n",
    "                batch = np.array(shuffled_memory[i:i + batch_size])\n",
    "                b_pobs = np.array(batch[:, 0].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                b_pact = np.array(batch[:, 1].tolist(), dtype=np.int32)\n",
    "                b_reward = np.array(batch[:, 2].tolist(), dtype=np.int32)\n",
    "                b_obs = np.array(batch[:, 3].tolist(), dtype=np.float32).reshape(batch_size, -1)\n",
    "                b_done = np.array(batch[:, 4].tolist(), dtype=np.bool)\n",
    "                q = Q(torch.from_numpy(b_pobs))\n",
    "                q_ = Q_b(torch.from_numpy(b_obs))\n",
    "                maxq = np.max(q_.data.numpy(),axis=1)\n",
    "                target = copy.deepcopy(q.data)\n",
    "                for j in range(batch_size):\n",
    "                    target[j, b_pact[j]] = b_reward[j] + gamma * maxq[j] * (not b_done[j])\n",
    "                    Q.zero_grad()\n",
    "                    loss_val = loss(q, target)\n",
    "                    total_loss += loss_val.data.item()\n",
    "                    loss_val.backward(retain_graph=True)\n",
    "                    optimizer.step()\n",
    "        if total_step % update_q_freq == 0:\n",
    "            Q_b = copy.deepcopy(Q)\n",
    "        if epsilon > epsilon_min and total_step > start_reduce_epsilon:\n",
    "            epsilon -= epsilon_decrease\n",
    "        total_reward += reward\n",
    "        pobs = obs\n",
    "        step += 1\n",
    "        total_step += 1\n",
    "    total_rewards.append(total_reward)\n",
    "    total_losses.append(total_loss)\n",
    "    if (epoch + 1) % show_log_freq == 0:\n",
    "        log_reward = sum(total_rewards[epoch + 1 - show_log_freq:]) / show_log_freq\n",
    "        log_loss = sum(total_losses[epoch + 1 - show_log_freq:]) / show_log_freq\n",
    "        elapsed_time = time.time() - start\n",
    "        start = time.time()\n",
    "        print('\\t'.join(map(str, [epoch + 1, epsilon, total_step, log_reward, log_loss, elapsed_time])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MXqxcvM5ZouL"
   },
   "outputs": [],
   "source": [
    "test_env = TradingEnvironment(test)\n",
    "pobs = env.reset()\n",
    "test_acts = []\n",
    "test_rewards = []\n",
    "for _ in range(len(test_env.data) - 1):\n",
    "    pact = Q(torch.from_numpy(np.array(pobs, dtype=np.float32).reshape(1, -1)))\n",
    "    pact = np.argmax(pact.data)\n",
    "    test_acts.append(pact.item())\n",
    "    obs, reward, done = test_env.step(pact.numpy())\n",
    "    test_rewards.append(reward)\n",
    "    pobs = obs\n",
    "    if done:\n",
    "        break\n",
    "test_worth = test_env.position_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V21jHiSeiWpu"
   },
   "outputs": [],
   "source": [
    "test_worth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9R343HbknwVe"
   },
   "outputs": [],
   "source": [
    "test_acts"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "StockTradingQN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
